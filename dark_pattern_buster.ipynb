{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense, Embedding, LSTM, GlobalMaxPooling1D\n",
        "\n",
        "# Load the dataset\n",
        "file_path = '/content/dataset.tsv'\n",
        "data = pd.read_csv(file_path, delimiter='\\t')\n",
        "\n",
        "# Constants\n",
        "max_len = 100  # Maximum length of text sequences\n",
        "max_words = 10000  # Maximum number of words to consider in the vocabulary\n",
        "\n",
        "# Split the data into features and labels\n",
        "X = data['text'].values\n",
        "y_binary = data['label'].values  # Binary classification labels\n",
        "y_category = data['Pattern Category'].values  # Multi-class classification labels\n",
        "\n",
        "# Tokenize the text\n",
        "tokenizer = Tokenizer(num_words=max_words)\n",
        "tokenizer.fit_on_texts(X)\n",
        "X_seq = tokenizer.texts_to_sequences(X)\n",
        "X_pad = pad_sequences(X_seq, maxlen=max_len)\n",
        "\n",
        "# Encode the multi-class labels\n",
        "label_encoder = LabelEncoder()\n",
        "y_category_encoded = label_encoder.fit_transform(y_category)\n",
        "\n",
        "# Split the data\n",
        "X_train, X_test, y_binary_train, y_binary_test, y_category_train, y_category_test = train_test_split(X_pad, y_binary, y_category_encoded, test_size=0.2)\n",
        "\n",
        "# Model Creation\n",
        "input_text = Input(shape=(max_len,))\n",
        "embedding = Embedding(max_words, 50)(input_text)\n",
        "lstm = LSTM(64, return_sequences=True)(embedding)\n",
        "global_max_pool = GlobalMaxPooling1D()(lstm)\n",
        "binary_pred = Dense(1, activation='sigmoid', name='binary_output')(global_max_pool)  # Binary classification output\n",
        "category_dense = Dense(64, activation='relu')(global_max_pool)\n",
        "category_pred = Dense(len(label_encoder.classes_), activation='softmax', name='category_output')(category_dense)  # Multi-class classification output\n",
        "\n",
        "model = Model(inputs=input_text, outputs=[binary_pred, category_pred])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss={'binary_output': 'binary_crossentropy', 'category_output': 'sparse_categorical_crossentropy'},\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Model Training\n",
        "model.fit(X_train, {'binary_output': y_binary_train, 'category_output': y_category_train}, epochs=15, validation_split=0.2)\n",
        "\n",
        "# Evaluation\n",
        "model.evaluate(X_test, {'binary_output': y_binary_test, 'category_output': y_category_test})\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sT6XsDGUgnjK",
        "outputId": "6d39ab9a-2cb1-4cf4-8b6b-0d8f7a8701d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "48/48 [==============================] - 8s 91ms/step - loss: 2.3170 - binary_output_loss: 0.6951 - category_output_loss: 1.6219 - binary_output_accuracy: 0.4957 - category_output_accuracy: 0.4937 - val_loss: 2.1812 - val_binary_output_loss: 0.6916 - val_category_output_loss: 1.4896 - val_binary_output_accuracy: 0.5066 - val_category_output_accuracy: 0.4934\n",
            "Epoch 2/15\n",
            "48/48 [==============================] - 3s 66ms/step - loss: 2.0805 - binary_output_loss: 0.6854 - category_output_loss: 1.3951 - binary_output_accuracy: 0.5362 - category_output_accuracy: 0.5030 - val_loss: 2.1579 - val_binary_output_loss: 0.6751 - val_category_output_loss: 1.4828 - val_binary_output_accuracy: 0.8011 - val_category_output_accuracy: 0.4934\n",
            "Epoch 3/15\n",
            "48/48 [==============================] - 3s 66ms/step - loss: 1.9489 - binary_output_loss: 0.6322 - category_output_loss: 1.3167 - binary_output_accuracy: 0.8275 - category_output_accuracy: 0.5030 - val_loss: 1.8669 - val_binary_output_loss: 0.5646 - val_category_output_loss: 1.3023 - val_binary_output_accuracy: 0.8833 - val_category_output_accuracy: 0.4934\n",
            "Epoch 4/15\n",
            "48/48 [==============================] - 4s 87ms/step - loss: 1.4650 - binary_output_loss: 0.4518 - category_output_loss: 1.0132 - binary_output_accuracy: 0.9516 - category_output_accuracy: 0.6410 - val_loss: 1.4629 - val_binary_output_loss: 0.4103 - val_category_output_loss: 1.0526 - val_binary_output_accuracy: 0.9469 - val_category_output_accuracy: 0.6419\n",
            "Epoch 5/15\n",
            "48/48 [==============================] - 3s 65ms/step - loss: 1.1161 - binary_output_loss: 0.3109 - category_output_loss: 0.8052 - binary_output_accuracy: 0.9715 - category_output_accuracy: 0.7100 - val_loss: 1.2311 - val_binary_output_loss: 0.3193 - val_category_output_loss: 0.9118 - val_binary_output_accuracy: 0.9443 - val_category_output_accuracy: 0.6472\n",
            "Epoch 6/15\n",
            "48/48 [==============================] - 3s 64ms/step - loss: 0.8638 - binary_output_loss: 0.2070 - category_output_loss: 0.6568 - binary_output_accuracy: 0.9847 - category_output_accuracy: 0.7697 - val_loss: 1.1345 - val_binary_output_loss: 0.2777 - val_category_output_loss: 0.8568 - val_binary_output_accuracy: 0.9204 - val_category_output_accuracy: 0.7135\n",
            "Epoch 7/15\n",
            "48/48 [==============================] - 3s 67ms/step - loss: 0.6665 - binary_output_loss: 0.1382 - category_output_loss: 0.5284 - binary_output_accuracy: 0.9894 - category_output_accuracy: 0.8288 - val_loss: 0.9660 - val_binary_output_loss: 0.2314 - val_category_output_loss: 0.7346 - val_binary_output_accuracy: 0.9363 - val_category_output_accuracy: 0.7666\n",
            "Epoch 8/15\n",
            "48/48 [==============================] - 4s 87ms/step - loss: 0.5342 - binary_output_loss: 0.1004 - category_output_loss: 0.4338 - binary_output_accuracy: 0.9914 - category_output_accuracy: 0.8527 - val_loss: 0.8680 - val_binary_output_loss: 0.2034 - val_category_output_loss: 0.6646 - val_binary_output_accuracy: 0.9337 - val_category_output_accuracy: 0.7798\n",
            "Epoch 9/15\n",
            "48/48 [==============================] - 3s 67ms/step - loss: 0.4196 - binary_output_loss: 0.0777 - category_output_loss: 0.3419 - binary_output_accuracy: 0.9947 - category_output_accuracy: 0.8918 - val_loss: 0.8675 - val_binary_output_loss: 0.2216 - val_category_output_loss: 0.6459 - val_binary_output_accuracy: 0.9231 - val_category_output_accuracy: 0.8196\n",
            "Epoch 10/15\n",
            "48/48 [==============================] - 3s 63ms/step - loss: 0.3468 - binary_output_loss: 0.0708 - category_output_loss: 0.2760 - binary_output_accuracy: 0.9907 - category_output_accuracy: 0.9330 - val_loss: 0.7655 - val_binary_output_loss: 0.1999 - val_category_output_loss: 0.5656 - val_binary_output_accuracy: 0.9231 - val_category_output_accuracy: 0.8700\n",
            "Epoch 11/15\n",
            "48/48 [==============================] - 3s 64ms/step - loss: 0.2572 - binary_output_loss: 0.0525 - category_output_loss: 0.2048 - binary_output_accuracy: 0.9954 - category_output_accuracy: 0.9549 - val_loss: 0.7331 - val_binary_output_loss: 0.1973 - val_category_output_loss: 0.5358 - val_binary_output_accuracy: 0.9231 - val_category_output_accuracy: 0.8674\n",
            "Epoch 12/15\n",
            "48/48 [==============================] - 5s 98ms/step - loss: 0.2009 - binary_output_loss: 0.0431 - category_output_loss: 0.1578 - binary_output_accuracy: 0.9960 - category_output_accuracy: 0.9708 - val_loss: 0.7241 - val_binary_output_loss: 0.1947 - val_category_output_loss: 0.5295 - val_binary_output_accuracy: 0.9284 - val_category_output_accuracy: 0.8700\n",
            "Epoch 13/15\n",
            "48/48 [==============================] - 5s 108ms/step - loss: 0.1642 - binary_output_loss: 0.0357 - category_output_loss: 0.1285 - binary_output_accuracy: 0.9980 - category_output_accuracy: 0.9741 - val_loss: 0.6928 - val_binary_output_loss: 0.1943 - val_category_output_loss: 0.4985 - val_binary_output_accuracy: 0.9337 - val_category_output_accuracy: 0.8992\n",
            "Epoch 14/15\n",
            "48/48 [==============================] - 3s 63ms/step - loss: 0.1483 - binary_output_loss: 0.0309 - category_output_loss: 0.1174 - binary_output_accuracy: 0.9967 - category_output_accuracy: 0.9754 - val_loss: 0.6931 - val_binary_output_loss: 0.2027 - val_category_output_loss: 0.4904 - val_binary_output_accuracy: 0.9310 - val_category_output_accuracy: 0.9019\n",
            "Epoch 15/15\n",
            "48/48 [==============================] - 3s 66ms/step - loss: 0.1111 - binary_output_loss: 0.0263 - category_output_loss: 0.0848 - binary_output_accuracy: 0.9987 - category_output_accuracy: 0.9827 - val_loss: 0.7036 - val_binary_output_loss: 0.1929 - val_category_output_loss: 0.5107 - val_binary_output_accuracy: 0.9363 - val_category_output_accuracy: 0.8912\n",
            "15/15 [==============================] - 0s 16ms/step - loss: 0.7564 - binary_output_loss: 0.2179 - category_output_loss: 0.5385 - binary_output_accuracy: 0.9216 - category_output_accuracy: 0.8623\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.7564239501953125,\n",
              " 0.21794772148132324,\n",
              " 0.5384761691093445,\n",
              " 0.9216101765632629,\n",
              " 0.8622881174087524]"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('Dark_Pattern_buster.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NXknDoHZiWZm",
        "outputId": "5c98ad34-eec6-4b96-d139-7f72487488a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    }
  ]
}